#!/usr/bin/env nextflow

workflow {

  


    LHS (
        params.LHS
        )
    // LHS_ext_jl(
    //     file("$moduleDir/lhs/sampling.jl"),
    //     setupLHS.out,
    //     )
    
    FORWARD_MODEL (
        LHS.out,
        file("$moduleDir/forward_model/synthetic_topo.asc") // TODO: Should be a config parameter
        )
    
    TRAIN_SURROGATE (
        LHS.out,
        FORWARD_MODEL.out
        )
  
    UQ_STATUS () // Create a named pipe for status updates
    SERVE_SURROGATE ( 
        UQ_STATUS.out.pipe,
        file("$moduleDir/surrogate/serve_surrogate.R"),
        TRAIN_SURROGATE.out,
        "ScalarGP_Umax"
        ) 
    MCMC ( 
        UQ_STATUS.out.pipe,
        file("$moduleDir/mcmc/MCMC_um.py"),
        "ScalarGP_Umax",
        file("$moduleDir/mcmc/calibration_data.csv")
        ) 
}



process LHS {

    container "file://$moduleDir/lhs/lhs_box.sif"

    publishDir "$moduleDir/outputs", mode: 'copy'
    

    input:
      val parameters

    output:
      file "lhs_output.csv"

    script:
    """
    #!/usr/bin/env julia 

    using QuasiMonteCarlo, Distributions
    using CSV
    using DataFrames


    d = ${parameters.bounds.size()}
    lb = [${parameters.bounds.parameter1[0]}, ${parameters.bounds.parameter2[0]}]
    ub = [${parameters.bounds.parameter1[1]}, ${parameters.bounds.parameter2[1]}]
    n = ${parameters.samples}  # Number of samples


    # # Generate LHS samples
    s = QuasiMonteCarlo.sample(n, lb, ub, LatinHypercubeSample())

    # # Convert to DataFrame (transpose and convert to regular matrix)
    df = DataFrame(Matrix(s'), :auto)  # Specify :auto for automatic column names


    # # Save the DataFrame to a CSV file without headers
    CSV.write("lhs_output.csv", df)


    """ 
}

process LHS_ext_jl {

    container "file://$moduleDir/lhs/lhs_box.sif"

    publishDir "$moduleDir/outputs", mode: 'copy'
    

    input:
      path jl_script
      path in

    output:
      file "lhs_output.csv"

    script:
    """
    
    julia --history-file=no ${jl_script} ${in} lhs_output.csv

    """ 
}

process FORWARD_MODEL {
    container "file://$moduleDir/forward_model/forward_model.sif"
    
    input:
      path lhs_samples
      path elevation_file

    output:
      file "Umax_MPM.csv" 

    script:
    """
    #!/usr/bin/env python3

    from psimpy.simulator import MassPointModel
    from psimpy.simulator import RunSimulator
    import numpy as np

    # Load the LHS samples
    train_samples = np.loadtxt("$lhs_samples", delimiter=',', skiprows=1)
    nsamples = train_samples.shape[0] 

    

    # Setup Mass Point Model
    MPM_M1 = MassPointModel()

    simulator = RunSimulator(
        simulator=MPM_M1.run,
        var_inp_parameter=[
            'coulomb_friction',
            'turbulent_friction'
            ],
        fix_inp={
            'elevation' : "$elevation_file",
            'x0' : 200,  # TODO Move to config parameter
            'y0' : 2000, # TODO Move to config parameter
            'dt' : 0.1   # TODO Move to config parameter
            }
        )

    # Run the simulations
    simulator.parallel_run(var_samples=train_samples)
    serial_output = simulator.outputs

    # Post-process the results
    U_res = np.ones(nsamples)
    # x_res = np.ones(nsamples)
    for i in range(nsamples):
            U_res[i] = serial_output[i][:,5].max()
            # x_res[i] = serial_output[i][:,1].max()

    np.savetxt("Umax_MPM.csv", U_res, delimiter=",")
    
    """
}

process TRAIN_SURROGATE {
    container "file://$moduleDir/surrogate/surrogate.sif"

    input:
    path design
    path response

    output:
    path "ScalarGP_Umax.rds" 

    script:
        """
        #!/usr/bin/env Rscript
        library("RobustGaSP")


        # Read input data
        design <- as.matrix(read.csv(file.path("$design"), header = TRUE))
        print(design)


        # Read output data
        response <- as.matrix(read.csv(file.path("$response"), header = FALSE))
        print(response)

        # Fit the Gaussian process model
        ScalarGP_Umax <- rgasp(design = design, response = response, lower_bound = TRUE)


        LOO <- leave_one_out_rgasp(ScalarGP_Umax)
        print(LOO)

        # Save the trained model using saveRDS
        saveRDS(ScalarGP_Umax, file = file.path("ScalarGP_Umax.rds"))

        """
}

process UQ_STATUS {
    script:
    """
    mkfifo status_info
    """

    output:
    path "status_info", emit: pipe
}

process SERVE_SURROGATE {
    container "file://$moduleDir/surrogate/surrogate.sif"
    cache 'lenient'

    input:
    path status
    path script
    path model
    val model_name

    

    script:
    """
    #!/bin/bash

    # Sleep 100000 represents the model server
    # which is started in the background
    # and its process ID is stored, inorder to kill later
    
    Rscript ${script} ${model} ${model_name} & 
    PID=\$! && echo "Model Server Started" && echo "complete" > $status
        
    # Wait for MCMC to finish | Look for "mcmc=0" in status
    cat $status
    
    # Stop model server (kill process)
    kill \$PID &> /dev/null
    echo "Model Server Stopped"
    rm $status
    """
}

process MCMC {
    conda "$moduleDir/mcmc/environment.yml"
    cache 'lenient'
    publishDir "$moduleDir/outputs", mode: 'copy'
    
    input:
    path status
    path script
    val model_name
    path calibration_data


    script:
    """
    # Wait for MODEL to start | Look for "model=1" in status
    cat $status
    
    echo "MCMC Started"
    python ${script} ${calibration_data} ${model_name}
    echo "MCMC Finished"
    # Store MCMC results
    
    echo "mcmc_complete" > $status
    """

    output:
    path "mcmc_trace.npy"
    path "mcmc_full_chain.npy"
}